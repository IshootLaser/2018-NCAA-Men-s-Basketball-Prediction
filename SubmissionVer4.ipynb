{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import compress\n",
    "from sklearn.externals import joblib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of regular season instance is 82041.\n",
      "The total number of tourney instance is 981.\n"
     ]
    }
   ],
   "source": [
    "df_seed = pd.read_csv(r'F:\\CODE\\NCAA 2018\\Stage2UpdatedDataFiles\\NCAATourneySeeds.csv')\n",
    "df_tourney_compact = pd.read_csv(r'F:\\CODE\\NCAA 2018\\DataFiles\\NCAATourneyCompactResults.csv')\n",
    "df_tourney_detail = pd.read_csv(r'F:\\CODE\\NCAA 2018\\DataFiles\\NCAATourneyDetailedResults.csv')\n",
    "df_reg_compact = pd.read_csv(r'F:\\CODE\\NCAA 2018\\DataFiles\\RegularSeasonCompactResults.csv')\n",
    "df_reg_detail = pd.read_csv(r'F:\\CODE\\NCAA 2018\\Stage2UpdatedDataFiles\\RegularSeasonDetailedResults.csv')\n",
    "df_Ordinal = pd.read_csv(r'F:\\CODE\\NCAA 2018\\MasseyOrdinals\\MasseyOrdinals_thruSeason2018_Day128.csv')\n",
    "df_rating = df_Ordinal[df_Ordinal['SystemName'].str.contains('WOL')]\n",
    "syslist = list(df_Ordinal['SystemName'].unique())\n",
    "df_seed['seed rank'] = df_seed['Seed'].apply(lambda x: int(x[1:3]))\n",
    "df_seed = df_seed[df_seed['Season'] >= 2003].drop('Seed', axis = 1)\n",
    "df_reg_compact = df_reg_compact[df_reg_compact['Season'] >= 2003]\n",
    "df_tourney_compact = df_tourney_compact.drop(['DayNum', 'WLoc', 'NumOT'], axis = 1)\n",
    "df_tourney_detail = df_tourney_detail.drop(['DayNum', 'WLoc', 'NumOT'], axis = 1)\n",
    "df_reg_compact = df_reg_compact.drop(['DayNum', 'WLoc', 'NumOT'], axis = 1)\n",
    "df_reg_detail = df_reg_detail.drop(['DayNum', 'WLoc', 'NumOT'], axis = 1)\n",
    "\n",
    "df_regular = df_reg_detail.merge(df_seed, left_on = ['WTeamID', 'Season'], right_on = ['TeamID', 'Season'], how = 'outer').drop('TeamID', axis = 1)\n",
    "df_regular = df_regular.rename(index = str, columns = {'seed rank': 'WSeed'})\n",
    "df_regular = df_regular.merge(df_seed, left_on = ['LTeamID', 'Season'], right_on = ['TeamID', 'Season'], how = 'outer').drop('TeamID', axis = 1)\n",
    "df_regular = df_regular.rename(index = str, columns = {'seed rank': 'LSeed'})\n",
    "fillna = {'WSeed': 17, 'LSeed': 17}\n",
    "df_regular = df_regular.fillna(value = fillna)\n",
    "df_regular = df_regular.dropna(how = 'any')\n",
    "print('The total number of regular season instance is {}.'.format(len(df_regular.index)))\n",
    "df_regular = df_regular.drop(['WScore', 'LScore'], axis = 1)\n",
    "\n",
    "df_tourney = df_tourney_detail.merge(df_seed, left_on = ['WTeamID', 'Season'], right_on = ['TeamID', 'Season'], how = 'outer').drop('TeamID', axis = 1)\n",
    "df_tourney = df_tourney.rename(index = str, columns = {'seed rank': 'WSeed'})\n",
    "df_tourney = df_tourney.merge(df_seed, left_on = ['LTeamID', 'Season'], right_on = ['TeamID', 'Season'], how = 'outer').drop('TeamID', axis = 1)\n",
    "df_tourney = df_tourney.rename(index = str, columns = {'seed rank': 'LSeed'})\n",
    "df_tourney = df_tourney.dropna(how = 'any')\n",
    "print('The total number of tourney instance is {}.'.format(len(df_tourney.index)))\n",
    "df_tourney = df_tourney.drop(['WScore', 'LScore'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate advanced stats for each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat((df_regular, df_tourney), axis = 0)\n",
    "Attributes = list(df_total.drop(['Season', 'WTeamID', 'LTeamID', 'WSeed', 'LSeed'], axis = 1).columns.values)\n",
    "# Win/lose points\n",
    "df_total['WPts'] = df_total.apply(lambda row: 2*row.WFGM + row.WFGM3 + row.WFTM, axis=1)\n",
    "df_total['LPts'] = df_total.apply(lambda row: 2*row.LFGM + row.LFGM3 + row.LFTM, axis=1)\n",
    "#Win/lose possession\n",
    "wPos = df_total.apply(lambda row: 0.96*(row.WFGA + row.WTO + 0.44*row.WFTA - row.WOR), axis=1)\n",
    "lPos = df_total.apply(lambda row: 0.96*(row.LFGA + row.LTO + 0.44*row.LFTA - row.LOR), axis=1)\n",
    "#Average possession per game\n",
    "df_total['Pos'] = (wPos+lPos)/2\n",
    "#Offensive efficiency\n",
    "df_total['WOffRtg'] = df_total.apply(lambda row: 100 * (row.WPts / row.Pos), axis=1)\n",
    "df_total['LOffRtg'] = df_total.apply(lambda row: 100 * (row.LPts / row.Pos), axis=1)\n",
    "#Defensive efficiency\n",
    "df_total['WDefRtg'] = df_total.LOffRtg\n",
    "df_total['LDefRtg'] = df_total.WOffRtg\n",
    "#Net Rating\n",
    "df_total['WNetRtg'] = df_total.apply(lambda row:(row.WOffRtg - row.WDefRtg), axis=1)\n",
    "df_total['LNetRtg'] = df_total.apply(lambda row:(row.LOffRtg - row.LDefRtg), axis=1)\n",
    "#Assist Ratio\n",
    "df_total['WAstR'] = df_total.apply(lambda row: 100 * row.WAst / (row.WFGA + 0.44*row.WFTA + row.WAst + row.WTO), axis=1)\n",
    "df_total['LAstR'] = df_total.apply(lambda row: 100 * row.LAst / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "# Turnover Ratio\n",
    "df_total['WTOR'] = df_total.apply(lambda row: 100 * row.WTO / (row.WFGA + 0.44*row.WFTA + row.WAst + row.WTO), axis=1)\n",
    "df_total['LTOR'] = df_total.apply(lambda row: 100 * row.LTO / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "#Shooting Percentage\n",
    "df_total['WTSP'] = df_total.apply(lambda row: 100 * row.WPts / (2 * (row.WFGA + 0.44 * row.WFTA)), axis=1)\n",
    "df_total['LTSP'] = df_total.apply(lambda row: 100 * row.LPts / (2 * (row.LFGA + 0.44 * row.LFTA)), axis=1)\n",
    "#Effective field goal\n",
    "df_total['WeFGP'] = df_total.apply(lambda row:(row.WFGM + 0.5 * row.WFGM3) / row.WFGA, axis=1)      \n",
    "df_total['LeFGP'] = df_total.apply(lambda row:(row.LFGM + 0.5 * row.LFGM3) / row.LFGA, axis=1)\n",
    "# FTA Rate\n",
    "df_total['WFTAR'] = df_total.apply(lambda row: row.WFTA / row.WFGA, axis=1)\n",
    "df_total['LFTAR'] = df_total.apply(lambda row: row.LFTA / row.LFGA, axis=1)\n",
    "# OREB%\n",
    "df_total['WORP'] = df_total.apply(lambda row: row.WOR / (row.WOR + row.LDR), axis=1)\n",
    "df_total['LORP'] = df_total.apply(lambda row: row.LOR / (row.LOR + row.WDR), axis=1)\n",
    "# DREB%\n",
    "df_total['WDRP'] = df_total.apply(lambda row: row.WDR / (row.WDR + row.LOR), axis=1)\n",
    "df_total['LDRP'] = df_total.apply(lambda row: row.LDR / (row.LDR + row.WOR), axis=1)\n",
    "#REB%\n",
    "df_total['WRP'] = df_total.apply(lambda row: (row.WDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1)\n",
    "df_total['LRP'] = df_total.apply(lambda row: (row.LDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1) \n",
    "Attributes.append('Pos')\n",
    "df_total = df_total.drop(columns = Attributes)\n",
    "df_total = df_total.reset_index()\n",
    "df_total = df_total.drop('index', axis = 1)\n",
    "\n",
    "winnerStats = list(compress(df_total.drop(['Season', 'WTeamID', 'LTeamID', 'WSeed'], axis = 1).columns.values, [x.startswith('W') for x in df_total.drop(['Season', 'WTeamID', 'LTeamID', 'WSeed'], axis = 1).columns.values]))\n",
    "loserStats = list(compress(df_total.drop(['Season', 'WTeamID', 'LTeamID', 'LSeed'], axis = 1).columns.values, [x.startswith('L') for x in df_total.drop(['Season', 'WTeamID', 'LTeamID', 'LSeed'], axis = 1).columns.values]))\n",
    "\n",
    "df_dummy = df_total[:-981]\n",
    "\n",
    "for year in df_total['Season'].unique():\n",
    "    df_dummy_1 = df_dummy[df_dummy['Season'] == year]\n",
    "    for team in pd.concat((df_dummy_1['WTeamID'], df_dummy_1['LTeamID'])).unique():\n",
    "        df_dummy_2 = df_dummy_1[(df_dummy_1['WTeamID'] == team)]\n",
    "        df_dummy_2_mean = df_dummy_2[winnerStats].mean().values\n",
    "        df_dummy_3 = df_dummy_1[(df_dummy_1['LTeamID'] == team)]\n",
    "        df_dummy_3_mean = df_dummy_3[loserStats].mean().values\n",
    "        if len(df_dummy_2.index) == 0:\n",
    "            TotalMean = df_dummy_3_mean\n",
    "        elif len(df_dummy_3.index) == 0:\n",
    "            TotalMean = df_dummy_2_mean\n",
    "        else:\n",
    "            TotalMean = (df_dummy_2_mean + df_dummy_3_mean) / 2\n",
    "        \n",
    "        index_W = df_total[(df_total['WTeamID'] == team) & (df_total['Season'] == year)].index\n",
    "        df_total.loc[index_W, winnerStats] = TotalMean\n",
    "        index_L = df_total[(df_total['LTeamID'] == team) & (df_total['Season'] == year)].index\n",
    "        df_total.loc[index_L, loserStats] = TotalMean\n",
    "\n",
    "for year in df_total['Season'].unique():\n",
    "    dummy = df_rating[df_rating['Season'] == year]\n",
    "    for team in dummy['TeamID'].unique():\n",
    "        dummy2 = dummy[(dummy['TeamID'] == team)]\n",
    "        OR = dummy2['OrdinalRank'].to_frame().values[-1]\n",
    "        index1 = df_total[(df_total['WTeamID'] == team) & (df_total['Season'] == year)].index\n",
    "        index2 = df_total[(df_total['LTeamID'] == team) & (df_total['Season'] == year)].index\n",
    "        if len(index1) != 0:\n",
    "            df_total.loc[index1, 'WOR'] = OR\n",
    "        if len(index2) != 0:\n",
    "            df_total.loc[index2, 'LOR'] = OR\n",
    "\n",
    "df_total = df_total.dropna(how = 'any')\n",
    "df_total.to_pickle('./df_total.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature = 28\n",
      "Number of training instance = 166024\n",
      "Number of CV instance = 29885\n",
      "Number of test instance = 16603\n",
      "Number of target instance = 124\n"
     ]
    }
   ],
   "source": [
    "winnerStats = list(compress(df_total.drop(['Season', 'WTeamID', 'LTeamID'], axis = 1).columns.values, [x.startswith('W') for x in df_total.drop(['Season', 'WTeamID', 'LTeamID'], axis = 1).columns.values]))\n",
    "loserStats = list(compress(df_total.drop(['Season', 'WTeamID', 'LTeamID'], axis = 1).columns.values, [x.startswith('L') for x in df_total.drop(['Season', 'WTeamID', 'LTeamID'], axis = 1).columns.values]))\n",
    "test_split = df_total[-981:].copy()\n",
    "test_index = test_split[test_split['Season'] >= 2017].index[0]\n",
    "\n",
    "df_winner = df_total[winnerStats].copy()\n",
    "df_loser = df_total[loserStats].copy()\n",
    "df_win = pd.concat([df_total[['Season', 'WTeamID', 'LTeamID']], df_winner, df_loser], axis = 1)\n",
    "df_lose = pd.concat([df_total[['Season', 'WTeamID', 'LTeamID']], df_loser, df_winner], axis = 1)\n",
    "df_win['label'] = 1\n",
    "df_lose['label'] = 0\n",
    "renamedict = dict(zip(loserStats+winnerStats, winnerStats+loserStats))\n",
    "df_lose = df_lose.rename(index = str, columns = renamedict).reset_index(drop = True)\n",
    "\n",
    "df_target = pd.concat([df_win.loc[test_index:], df_lose.loc[test_index:]])\n",
    "droplist = ['Season', 'WTeamID', 'LTeamID', 'label']\n",
    "df_data = pd.concat((df_win, df_lose))\n",
    "df_data_x = df_data.drop(droplist, axis = 1)\n",
    "df_data_y = df_data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data_x, df_data_y, test_size = 0.1)\n",
    "_, X_val, _, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "\n",
    "X_target = df_target.drop(droplist, axis = 1)\n",
    "y_target = df_target['label']\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "X_target_scaled = scaler.fit_transform(X_target)\n",
    "print('Number of feature = {}'.format(len(X_train.columns.values)))\n",
    "print('Number of training instance = {}'.format(len(df_data.index)))\n",
    "print('Number of CV instance = {}'.format(len(X_val.index)))\n",
    "print('Number of test instance = {}'.format(len(X_test.index)))\n",
    "print('Number of target instance = {}'.format(len(X_target.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple baseline estimator with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is: -0.48694866110522406.\n",
      "Best parameter is: {'C': 0.10000000000000001}\n",
      "Test Log loss is 0.4869121827651006\n",
      "CV loss is 0.48540220679931967\n",
      "Target loss is 0.5331412789955903\n"
     ]
    }
   ],
   "source": [
    "lrclf = LogisticRegression()\n",
    "params_dict = {'C': np.logspace(start=-5,stop=3,num=5)}\n",
    "grid_search = GridSearchCV(lrclf, params_dict, scoring = 'neg_log_loss',\n",
    "              cv = 3, refit = True)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print('Best score is: {}.\\nBest parameter is: {}'.format(grid_search.best_score_,grid_search.best_params_))\n",
    "y_pred_test = grid_search.predict_proba(X_test_scaled)[:,1]\n",
    "print('Test Log loss is {}'.format(log_loss(y_test.values.reshape(-1,1), y_pred_test.reshape(-1,1))))\n",
    "y_pred_CV = grid_search.predict_proba(X_val_scaled)[:,1]\n",
    "print('CV loss is {}'.format(log_loss(y_val.values.reshape(-1,1), y_pred_CV.reshape(-1,1))))\n",
    "y_pred_target = grid_search.predict_proba(X_target_scaled)[:,1]\n",
    "print('Target loss is {}'.format(log_loss(y_target.values.reshape(-1,1), y_pred_target.reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to get better results using a simple fully connected network.<br>\n",
    "I added dropout to suppress overfitting. I have tried dropout range 0.2~0.9 but I found that a slight dropout (0.9) works better in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch 0 train loss:  0.7490081787109375\n",
      "Current epoch 0 test loss:   0.7459973096847534\n",
      "Current epoch 0 CV loss:     0.7483544945716858\n",
      "Current epoch 0 target loss: 0.7642732858657837\n",
      "Current epoch 50 train loss:  0.5640243291854858\n",
      "Current epoch 50 test loss:   0.5641112923622131\n",
      "Current epoch 50 CV loss:     0.5666115283966064\n",
      "Current epoch 50 target loss: 0.5841959714889526\n",
      "Current epoch 100 train loss:  0.5159159898757935\n",
      "Current epoch 100 test loss:   0.5169592499732971\n",
      "Current epoch 100 CV loss:     0.5140306353569031\n",
      "Current epoch 100 target loss: 0.5515422224998474\n",
      "Current epoch 150 train loss:  0.5008491277694702\n",
      "Current epoch 150 test loss:   0.5047860145568848\n",
      "Current epoch 150 CV loss:     0.5003970861434937\n",
      "Current epoch 150 target loss: 0.5457720160484314\n",
      "Current epoch 200 train loss:  0.4950259029865265\n",
      "Current epoch 200 test loss:   0.49710455536842346\n",
      "Current epoch 200 CV loss:     0.4942770004272461\n",
      "Current epoch 200 target loss: 0.5554591417312622\n",
      "Current epoch 250 train loss:  0.49151232838630676\n",
      "Current epoch 250 test loss:   0.4937417209148407\n",
      "Current epoch 250 CV loss:     0.4894888401031494\n",
      "Current epoch 250 target loss: 0.5250810980796814\n",
      "Current epoch 300 train loss:  0.48964357376098633\n",
      "Current epoch 300 test loss:   0.4923737049102783\n",
      "Current epoch 300 CV loss:     0.48900818824768066\n",
      "Current epoch 300 target loss: 0.5240166187286377\n",
      "Current epoch 350 train loss:  0.488035649061203\n",
      "Current epoch 350 test loss:   0.49073854088783264\n",
      "Current epoch 350 CV loss:     0.4862542748451233\n",
      "Current epoch 350 target loss: 0.5226752758026123\n",
      "Current epoch 400 train loss:  0.4870690405368805\n",
      "Current epoch 400 test loss:   0.4899212121963501\n",
      "Current epoch 400 CV loss:     0.4857136309146881\n",
      "Current epoch 400 target loss: 0.5330201387405396\n",
      "Current epoch 450 train loss:  0.4862591624259949\n",
      "Current epoch 450 test loss:   0.4889387786388397\n",
      "Current epoch 450 CV loss:     0.48509547114372253\n",
      "Current epoch 450 target loss: 0.5345017313957214\n",
      "Current epoch 500 train loss:  0.48508912324905396\n",
      "Current epoch 500 test loss:   0.4896151125431061\n",
      "Current epoch 500 CV loss:     0.4839138686656952\n",
      "Current epoch 500 target loss: 0.5363423824310303\n",
      "Current epoch 550 train loss:  0.4847746789455414\n",
      "Current epoch 550 test loss:   0.4893886148929596\n",
      "Current epoch 550 CV loss:     0.4838513135910034\n",
      "Current epoch 550 target loss: 0.5348422527313232\n",
      "Current epoch 600 train loss:  0.4841168224811554\n",
      "Current epoch 600 test loss:   0.4877660870552063\n",
      "Current epoch 600 CV loss:     0.4828621447086334\n",
      "Current epoch 600 target loss: 0.5377076864242554\n",
      "Current epoch 650 train loss:  0.48387420177459717\n",
      "Current epoch 650 test loss:   0.4885900914669037\n",
      "Current epoch 650 CV loss:     0.48268210887908936\n",
      "Current epoch 650 target loss: 0.5298305749893188\n",
      "Current epoch 700 train loss:  0.483642578125\n",
      "Current epoch 700 test loss:   0.4886205792427063\n",
      "Current epoch 700 CV loss:     0.48267441987991333\n",
      "Current epoch 700 target loss: 0.5337445735931396\n",
      "Current epoch 750 train loss:  0.4831925332546234\n",
      "Current epoch 750 test loss:   0.488192617893219\n",
      "Current epoch 750 CV loss:     0.48238101601600647\n",
      "Current epoch 750 target loss: 0.5332155823707581\n",
      "Current epoch 800 train loss:  0.482915461063385\n",
      "Current epoch 800 test loss:   0.48774453997612\n",
      "Current epoch 800 CV loss:     0.4819245934486389\n",
      "Current epoch 800 target loss: 0.5338084101676941\n",
      "Current epoch 850 train loss:  0.4828159511089325\n",
      "Current epoch 850 test loss:   0.4878639876842499\n",
      "Current epoch 850 CV loss:     0.48081061244010925\n",
      "Current epoch 850 target loss: 0.5408636331558228\n",
      "Current epoch 900 train loss:  0.4824100136756897\n",
      "Current epoch 900 test loss:   0.48773011565208435\n",
      "Current epoch 900 CV loss:     0.4813103973865509\n",
      "Current epoch 900 target loss: 0.5399263501167297\n",
      "Current epoch 950 train loss:  0.48189982771873474\n",
      "Current epoch 950 test loss:   0.48826006054878235\n",
      "Current epoch 950 CV loss:     0.48062774538993835\n",
      "Current epoch 950 target loss: 0.5443755388259888\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "n_inputs = 28\n",
    "n_hidden1 = 28\n",
    "n_hidden2 = 28\n",
    "n_hidden3 = 28\n",
    "n_output = 1\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = 'X')\n",
    "y = tf.placeholder(tf.float32, shape = (None, n_output), name = 'y')\n",
    "hidden1 = fully_connected(X, n_hidden1)\n",
    "BN_1 = tf.contrib.layers.batch_norm(hidden1, scale = True)\n",
    "dropout_1 = tf.nn.dropout(BN_1, keep_prob = 0.9)\n",
    "hidden2 = fully_connected(dropout_1, n_hidden2)\n",
    "hidden3 = fully_connected(hidden2, n_hidden3)\n",
    "logits = fully_connected(hidden3, n_output, activation_fn = tf.nn.sigmoid)\n",
    "xentropy = tf.losses.log_loss(labels = y, predictions = logits)\n",
    "loss = tf.reduce_mean(xentropy, name = 'loss')\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep = 999)\n",
    "n_epochs = 1000\n",
    "error = []\n",
    "with tf.Session(config = config) as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict = {X: X_train_scaled, y: y_train.values.reshape(-1,1)})\n",
    "        if epoch % 50 == 0:\n",
    "            log_loss_train = loss.eval(feed_dict = {X: X_train_scaled, y: y_train.values.reshape(-1,1)})\n",
    "            log_loss_test = loss.eval(feed_dict = {X: X_test_scaled, y: y_test.values.reshape(-1,1)})\n",
    "            log_loss_CV = loss.eval(feed_dict = {X: X_val_scaled, y: y_val.values.reshape(-1,1)})\n",
    "            log_loss_target = loss.eval(feed_dict = {X: X_target_scaled, y: y_target.values.reshape(-1,1)})\n",
    "            print('Current epoch {} train loss:  {}'.format(epoch, log_loss_train))\n",
    "            print('Current epoch {} test loss:   {}'.format(epoch, log_loss_test))\n",
    "            print('Current epoch {} CV loss:     {}'.format(epoch, log_loss_CV))\n",
    "            print('Current epoch {} target loss: {}'.format(epoch, log_loss_target))\n",
    "            error.append([epoch, log_loss_train, log_loss_test, log_loss_CV, log_loss_target])\n",
    "            save_path = saver.save(sess, './BasicNN/3L_NN_Model_{}.ckpt'.format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the model loss curve. It seems like the best model is at around 300~500 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAD8CAYAAAAVFP+hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1555cb392b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = np.array(error)\n",
    "plt.plot(error[:,0], error[:,1], label = 'Train')\n",
    "plt.plot(error[:,0], error[:,2], label = 'Test')\n",
    "plt.plot(error[:,0], error[:,3], label = 'CV')\n",
    "plt.plot(error[:,0], error[:,4], label = 'target')\n",
    "plt.legend('Train')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code prepare data for the submission set for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fillsubmit = df_total\n",
    "df_submit = pd.read_csv(r'F:\\CODE\\NCAA 2018\\SampleSubmissionStage2.csv')\n",
    "df_submit['Season'] = df_submit['ID'].apply(lambda x: int(x[:4]))\n",
    "df_submit['lowerTeam'] = df_submit['ID'].apply(lambda x: int(x[5:9]))\n",
    "df_submit['higherTeam'] = df_submit['ID'].apply(lambda x: int(x[10:]))\n",
    "df_submit = pd.concat((df_submit, pd.DataFrame(columns = winnerStats + loserStats)), axis = 1)\n",
    "\n",
    "for year in df_submit['Season'].unique():\n",
    "    dummy = df_submit[df_submit['Season'] == year]\n",
    "    for team in dummy['lowerTeam'].unique():\n",
    "        dummy1 = df_fillsubmit[((df_fillsubmit['WTeamID'] == team) | (df_fillsubmit['LTeamID'] == team)) & (df_fillsubmit['Season'] == year)]\n",
    "        index = dummy1.index.values[0]\n",
    "        if dummy1.loc[index, 'WTeamID'] == team:\n",
    "            lower = dummy1.loc[index, winnerStats].values\n",
    "        else:\n",
    "            lower = dummy1.loc[index, loserStats].values\n",
    "        index = df_submit[(df_submit['Season'] == year) & (df_submit['lowerTeam'] == team)].index\n",
    "        df_submit.loc[index, winnerStats] = lower\n",
    "\n",
    "for year in df_submit['Season'].unique():\n",
    "    dummy = df_submit[df_submit['Season'] == year]\n",
    "    for team in dummy['higherTeam'].unique():\n",
    "        dummy1 = df_fillsubmit[((df_fillsubmit['WTeamID'] == team) | (df_fillsubmit['LTeamID'] == team)) & (df_fillsubmit['Season'] == year)]\n",
    "        index = dummy1.index.values[0]\n",
    "        if dummy1.loc[index, 'WTeamID'] == team:\n",
    "            higher = dummy1.loc[index, winnerStats].values\n",
    "        else:\n",
    "            higher = dummy1.loc[index, loserStats].values\n",
    "        index = df_submit[(df_submit['Season'] == year) & (df_submit['higherTeam'] == team)].index\n",
    "        df_submit.loc[index, loserStats] = higher\n",
    "\n",
    "df_submit = df_submit.drop(['Season', 'lowerTeam', 'higherTeam'], axis = 1)\n",
    "\n",
    "reorder = X_train.columns.values\n",
    "dummy = df_submit[reorder]\n",
    "dummy.head()\n",
    "df_submit = pd.concat((df_submit.drop(reorder, axis = 1), dummy), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction with logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "CurrentTime = str(now.month) + str(now.day) + str(now.hour) + str(now.minute)\n",
    "submissionlrclf = np.clip(grid_search.predict_proba(df_submit[reorder])[:,1], 0.05, 0.95)\n",
    "df_submitform = pd.read_csv(r'F:\\CODE\\NCAA 2018\\SampleSubmissionStage2.csv')\n",
    "df_submitform['Pred'] = submissionlrclf\n",
    "df_submitform.to_csv('Logistic Regression Model Submission_{}.csv'.format(CurrentTime), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction with neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./BasicNN/3L_NN_Model_500.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config = config) as sess:\n",
    "    saver.restore(sess, './BasicNN/3L_NN_Model_500.ckpt')\n",
    "    df_submit_scaled = scaler.fit_transform(df_submit[reorder])\n",
    "    submissionNN = logits.eval(feed_dict = {X: df_submit_scaled})\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "CurrentTime = str(now.month) + str(now.day) + str(now.hour) + str(now.minute)\n",
    "df_submitform = pd.read_csv(r'F:\\CODE\\NCAA 2018\\SampleSubmissionStage2.csv')\n",
    "df_submitform['Pred'] = submissionNN\n",
    "df_submitform.to_csv('NN_{} Model Submission.csv'.format(CurrentTime), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
